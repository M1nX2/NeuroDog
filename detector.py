import os
import cv2
import numpy as np
import torch
import torch.nn as nn
from ultralytics import YOLO
from tqdm import tqdm
import itertools
import math
from collections import deque

# === CONFIGURATION ===
DEVICE = torch.device('cpu')  # –¢–æ–ª—å–∫–æ CPU –¥–ª—è Docker
NUM_KEYPOINTS = 20
SEQ_LENGTH = 120

ALL_DIST_PAIRS = list(itertools.combinations(range(NUM_KEYPOINTS), 2))
ALL_ANGLE_TRIPLES = list(itertools.combinations(range(NUM_KEYPOINTS), 3))

# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π (–æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ –ø—É—Ç–∏ –¥–ª—è Docker)
pose_model = YOLO("models/dog_pose_model_yolo8_14.pt")
dog_detect_model = YOLO("models/dog_detect_model_yolo8_450ep.pt")


class LSTMPoseClassifier(nn.Module):
    def __init__(self, input_size, lstm_hidden=256, num_lstm_layers=3, fc_layers=[512, 256]):
        super().__init__()
        # –ó–∞–º–µ–Ω–∞ GRU –Ω–∞ LSTM
        self.lstm = nn.LSTM(
            input_size=input_size,
            hidden_size=lstm_hidden,
            num_layers=num_lstm_layers,
            batch_first=True,
            dropout=0.3 if num_lstm_layers > 1 else 0,
            bidirectional=True
        )
        # –ú–µ—Ö–∞–Ω–∏–∑–º –≤–Ω–∏–º–∞–Ω–∏—è (—Ä–∞–±–æ—Ç–∞–µ—Ç —Å –≤—ã—Ö–æ–¥–∞–º–∏ LSTM: [batch, seq, hidden*2])
        self.attention = nn.Sequential(
            nn.Linear(lstm_hidden * 2, 128),
            nn.Tanh(),
            nn.Linear(128, 1, bias=False)
        )
        # –ì–ª—É–±–æ–∫–∞—è –ø–æ–ª–Ω–æ—Å–≤—è–∑–Ω–∞—è —á–∞—Å—Ç—å
        fc_modules = []
        in_features = lstm_hidden * 2  # bidirectional –¥–∞—ë—Ç —É–¥–≤–æ–µ–Ω–Ω—ã–π —Ä–∞–∑–º–µ—Ä
        for out_features in fc_layers:
            fc_modules.extend([
                nn.Linear(in_features, out_features),
                nn.BatchNorm1d(out_features),
                nn.ReLU(),
                nn.Dropout(0.3)
            ])
            in_features = out_features
        self.fc = nn.Sequential(*fc_modules)
        self.classifier = nn.Linear(in_features, 1)

    def forward(self, x):
        # x: [batch, seq_len, input_size]
        # LSTM –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç (outputs, (h_n, c_n))
        outputs, (h_n, c_n) = self.lstm(x)  # [batch, seq_len, hidden*2]
        # Attention: —Å—á–∏—Ç–∞–µ–º –≤–µ—Å–∞ –ø–æ –≤—Ä–µ–º–µ–Ω–Ω–æ–π —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç–∏ (seq_len)
        # attention(outputs) -> [batch, seq_len, 1]
        att_weights = torch.softmax(self.attention(outputs), dim=1)
        # –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –≤–µ–∫—Ç–æ—Ä: —Å—É–º–º–∞ –ø–æ seq_len
        context = torch.sum(att_weights * outputs, dim=1)  # [batch, hidden*2]
        features = self.fc(context)  # [batch, last_fc_dim]
        return self.classifier(features)  # [batch, 1]


def extract_structured_features(keypoints):
    """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: –¥–ª—è –≤—Å–µ—Ö –ø–∞—Ä —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è, –¥–ª—è –≤—Å–µ—Ö —Ç—Ä–æ–µ–∫ —É–≥–ª—ã."""
    features = []
    max_idx = NUM_KEYPOINTS - 1
    
    # –†–∞—Å—Å—Ç–æ—è–Ω–∏—è –º–µ–∂–¥—É –ø–∞—Ä–∞–º–∏
    for i, j in ALL_DIST_PAIRS:
        if i < len(keypoints) and j < len(keypoints):
            dist = np.linalg.norm(keypoints[i, :2] - keypoints[j, :2])
        else:
            dist = 0.0
        features.extend([
            i / max_idx,
            j / max_idx,
            dist / 500.0
        ])
    
    # –£–≥–ª—ã –º–µ–∂–¥—É —Ç—Ä–æ–∏—Ü–∞–º–∏
    for i, j, k in ALL_ANGLE_TRIPLES:
        angle = 0.0
        if i < len(keypoints) and j < len(keypoints) and k < len(keypoints):
            vec_ij = keypoints[i, :2] - keypoints[j, :2]
            vec_kj = keypoints[k, :2] - keypoints[j, :2]
            norm_ij = np.linalg.norm(vec_ij)
            norm_kj = np.linalg.norm(vec_kj)
            if norm_ij > 1e-6 and norm_kj > 1e-6:
                cosine = np.dot(vec_ij, vec_kj) / (norm_ij * norm_kj)
                angle = np.arccos(np.clip(cosine, -1.0, 1.0))
        features.extend([
            i / max_idx,
            j / max_idx,
            k / max_idx,
            angle / np.pi
        ])
    
    return np.array(features, dtype=np.float32)


class DefecationDetector:
    def __init__(self, lstm_path, dog_detect_model, pose_model, window_size=SEQ_LENGTH, threshold=0.7, smooth=5, progress_callback=None, frame_skip=1):
        self.device = DEVICE
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π
        self.dog_detect_model = dog_detect_model
        self.pose_model = pose_model
        self.human_detect_model = YOLO("yolov8n.pt")
        self.human_pose_model = YOLO("yolov8s-pose.pt")
        
        self.net = self._load_lstm(lstm_path)
        self.window = deque(maxlen=window_size)
        self.threshold = threshold
        self.smooth = smooth
        self.hist = []
        self.progress_callback = progress_callback  # Callback –¥–ª—è –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
        self.frame_skip = frame_skip  # –ü—Ä–æ–ø—É—Å–∫–∞—Ç—å –∫–∞–∂–¥—ã–π N-–π –∫–∞–¥—Ä –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è (1 = –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –≤—Å–µ –∫–∞–¥—Ä—ã)
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤—Å–µ—Ö –∞—Ç—Ä–∏–±—É—Ç–æ–≤ —Å–æ—Å—Ç–æ—è–Ω–∏—è
        self.alert = False
        self.defecation_confirmed = False
        self.cleaning_detected = False
        self.prev_dog_feats = None
        self.defecation_point = None
        self.cleaning_min_duration = 2
        self.cleaning_radius = 50
        self.last_defecation_frame = 0
        self.defecation_point_fixed = None
        self.violation_active = False
        self.violation_periods = []  # –°–ø–∏—Å–æ–∫ –ø–µ—Ä–∏–æ–¥–æ–≤ –Ω–∞—Ä—É—à–µ–Ω–∏–π [(start_frame, end_frame)]
        self.violation_start_frame = None  # –ù–∞—á–∞–ª–æ —Ç–µ–∫—É—â–µ–≥–æ –ø–µ—Ä–∏–æ–¥–∞ –Ω–∞—Ä—É—à–µ–Ω–∏—è
        
        # –¶–≤–µ—Ç–æ–≤—ã–µ –ø–∞–ª–∏—Ç—Ä—ã
        self.dog_keypoint_colors = self._generate_color_palette(NUM_KEYPOINTS)
        self.human_keypoint_colors = self._generate_color_palette(17)
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –≤—Ä–µ–º–µ–Ω–∏ (–≤ –∫–∞–¥—Ä–∞—Ö)
        self.fps = 30  # –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é, –æ–±–Ω–æ–≤–∏—Ç—Å—è –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∏–¥–µ–æ
        self.defecation_min_duration_frames = 2 * self.fps  # 2 —Å–µ–∫—É–Ω–¥—ã –¥–ª—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è –¥–µ—Ñ–µ–∫–∞—Ü–∏–∏
        self.cleaning_timeout_frames = 60 * self.fps  # 1 –º–∏–Ω—É—Ç–∞ –æ–∂–∏–¥–∞–Ω–∏—è —É–±–æ—Ä–∫–∏ –æ—Ç —Ö–æ–∑—è–∏–Ω–∞
        self.cleaning_min_duration_frames = 5 * self.fps  # 5 —Å–µ–∫—É–Ω–¥ –¥–ª—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è —É–±–æ—Ä–∫–∏
        self.min_defecation_interval_frames = 20 * self.fps  # 20 —Å–µ–∫—É–Ω–¥ –º–µ–∂–¥—É –¥–µ—Ñ–µ–∫–∞—Ü–∏—è–º–∏
        
        # –°—á–µ—Ç—á–∏–∫–∏ –∫–∞–¥—Ä–æ–≤
        self.alert_frame_start = None
        self.defecation_frame_fixed = None
        self.cleaning_frame_start = None

    def _generate_color_palette(self, n_colors):
        palette = []
        for hue in np.linspace(0, 179, n_colors):
            color = np.uint8([[[hue, 255, 255]]])
            bgr_color = cv2.cvtColor(color, cv2.COLOR_HSV2BGR)[0][0]
            palette.append(tuple(map(int, bgr_color)))
        return palette

    def _load_lstm(self, path):
        base_feat_len = len(ALL_DIST_PAIRS) * 3 + len(ALL_ANGLE_TRIPLES) * 4
        total_feat_len = base_feat_len * 2
        model = LSTMPoseClassifier(input_size=total_feat_len).to(self.device)
        state = torch.load(path, map_location='cpu')
        model.load_state_dict(state)
        model.eval()
        return model

    def _get_detections(self, frame, target_class="dog"):
        """–î–µ—Ç–µ–∫—Ü–∏—è –æ–±—ä–µ–∫—Ç–æ–≤ —Å –ø–æ–Ω–∏–∂–µ–Ω–Ω—ã–º –ø–æ—Ä–æ–≥–æ–º –¥–ª—è —Å–æ–±–∞–∫"""
        min_conf = 0.3 if target_class == "dog" else 0.5
        model = self.human_detect_model if target_class == "person" else self.dog_detect_model
        results = model(frame, verbose=False)[0]
        detections = []
        
        for box, cls, conf in zip(results.boxes.xyxy.cpu().numpy(), 
                                  results.boxes.cls.cpu().numpy(), 
                                  results.boxes.conf.cpu().numpy()):
            if conf < min_conf:
                continue
            x1, y1, x2, y2 = map(int, box)
            w, h = x2 - x1, y2 - y1
            
            # –§–∏–ª—å—Ç—Ä –ø–æ —Ä–∞–∑–º–µ—Ä—É
            if target_class == "person":
                if w < 100 or h < 100:
                    continue
            else:
                if w < 30 or h < 30:
                    continue
            
            if target_class == "person":
                if int(cls) == 0:
                    detections.append(([x1, y1, w, h], float(conf), "person"))
            else:
                if results.names[int(cls)] == target_class:
                    detections.append(([x1, y1, w, h], float(conf), target_class))
        
        return detections

    def _calculate_defecation_point(self, dog_kps):
        """–†–∞—Å—á–µ—Ç —Ç–æ—á–∫–∏ –¥–µ—Ñ–µ–∫–∞—Ü–∏–∏"""
        # –ï—Å–ª–∏ —Ç–æ—á–∫–∞ —É–∂–µ –∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–∞ - –Ω–µ –º–µ–Ω—è–µ–º –µ—ë
        if self.defecation_point_fixed:
            return self.defecation_point_fixed
        
        # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: —Ç–æ—á–∫–∞ 11 (–∞–Ω—É—Å)
        if len(dog_kps) > 11 and dog_kps[11][0] > 0 and dog_kps[11][1] > 0:
            return (int(dog_kps[11][0]), int(dog_kps[11][1]))
        return None

    def _is_hand_near_defecation_point(self, human_kps, defecation_point):
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –æ—Ç —Ä—É–∫ –¥–æ —Ç–æ—á–∫–∏ –¥–µ—Ñ–µ–∫–∞—Ü–∏–∏"""
        if defecation_point is None or human_kps is None:
            return False
        
        # –ò–Ω–¥–µ–∫—Å—ã –∑–∞–ø—è—Å—Ç–µ–π: 9 (–ª–µ–≤–æ–µ), 10 (–ø—Ä–∞–≤–æ–µ)
        left_wrist = None
        right_wrist = None
        
        if len(human_kps) > 9 and human_kps[9][0] > 0:
            left_wrist = human_kps[9]
        if len(human_kps) > 10 and human_kps[10][0] > 0:
            right_wrist = human_kps[10]
        
        for wrist in [left_wrist, right_wrist]:
            if wrist is not None:
                distance = math.sqrt((wrist[0] - defecation_point[0])**2 + 
                                    (wrist[1] - defecation_point[1])**2)
                if distance < self.cleaning_radius:
                    return True
        return False

    def _handle_no_dog_detection(self, vis_frame):
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è —Å–æ–±–∞–∫–∏ –±–µ–∑ –≤–∏–∑—É–∞–ª—å–Ω–æ–≥–æ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è"""
        # –†–∞–∑–º–µ—Ä –æ–¥–Ω–æ–≥–æ –≤–µ–∫—Ç–æ—Ä–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        feat_len = len(ALL_DIST_PAIRS) * 3 + len(ALL_ANGLE_TRIPLES) * 4
        # –°–æ–∑–¥–∞–µ–º –Ω—É–ª–µ–≤–æ–π –≤–µ–∫—Ç–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        zero = np.zeros(feat_len)
        # –î–æ–±–∞–≤–ª—è–µ–º –≤ –æ–∫–Ω–æ –∫–æ–Ω–∫–∞—Ç–µ–Ω–∞—Ü–∏—é –Ω—É–ª–µ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
        self.window.append(np.concatenate([zero, zero]))
        # –°–±—Ä–∞—Å—ã–≤–∞–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        self.prev_dog_feats = None
        # –°–±—Ä–æ—Å —Å—Ç–∞—Ç—É—Å–∞ –¥–µ—Ñ–µ–∫–∞—Ü–∏–∏ –ø—Ä–∏ –ø–æ—Ç–µ—Ä–µ —Å–æ–±–∞–∫–∏
        self.alert = False
        self.alert_frame_start = None
        self.defecation_confirmed = False
        return vis_frame

    def process_frame(self, frame, frame_count):
        vis_frame = frame.copy()
        h, w = frame.shape[:2]
        
        # === –û–ë–†–ê–ë–û–¢–ö–ê –õ–Æ–î–ï–ô ===
        human_detections = self._get_detections(vis_frame, "person")
        
        # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –≤—Å–µ—Ö –¥–µ—Ç–µ–∫—Ü–∏–π –ª—é–¥–µ–π
        for det in human_detections:
            bbox, conf, cls = det
            x1, y1, w_det, h_det = bbox
            x2, y2 = x1 + w_det, y1 + h_det
            cv2.rectangle(vis_frame, (x1, y1), (x2, y2), (255, 0, 0), 2)
            cv2.putText(vis_frame, f"{cls}: {conf:.2f}", (x1, y1 - 10),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–ª—é—á–µ–≤—ã—Ö —Ç–æ—á–µ–∫ –ª—é–¥–µ–π
        for det in human_detections:
            bbox, conf, cls = det
            x1, y1, w_det, h_det = bbox
            x2, y2 = x1 + w_det, y1 + h_det
            if w_det >= 10 and h_det >= 10:
                cropped_human = frame[y1:y2, x1:x2]
                if cropped_human.size > 0:
                    pose_results = self.human_pose_model(cropped_human, verbose=False)[0]
                    if pose_results.keypoints is not None and len(pose_results.keypoints) > 0:
                        kps = pose_results.keypoints[0].xy[0].cpu().numpy()
                        kps[:, 0] += x1
                        kps[:, 1] += y1
                        
                        # –û—Ç—Ä–∏—Å–æ–≤–∫–∞ –∫–ª—é—á–µ–≤—ã—Ö —Ç–æ—á–µ–∫ —á–µ–ª–æ–≤–µ–∫–∞
                        for idx_pt, (px, py) in enumerate(kps):
                            if idx_pt < 17:
                                color = self.human_keypoint_colors[idx_pt]
                                cv2.circle(vis_frame, (int(px), int(py)), 4, color, -1)
        
        # === –û–ë–†–ê–ë–û–¢–ö–ê –°–û–ë–ê–ö ===
        dog_detections = self._get_detections(vis_frame, "dog")
        full_kps = None
        
        # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –≤—Å–µ—Ö –¥–µ—Ç–µ–∫—Ü–∏–π —Å–æ–±–∞–∫
        for det in dog_detections:
            bbox, conf, cls = det
            x1, y1, w_det, h_det = bbox
            x2, y2 = x1 + w_det, y1 + h_det
            cv2.rectangle(vis_frame, (x1, y1), (x2, y2), (0, 165, 255), 2)
            cv2.putText(vis_frame, f"{cls}: {conf:.2f}", (x1, y1 - 10),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 165, 255), 2)
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–∞–º–æ–π –Ω–∞–¥–µ–∂–Ω–æ–π –¥–µ—Ç–µ–∫—Ü–∏–∏ —Å–æ–±–∞–∫–∏
        if dog_detections:
            # –í—ã–±–∏—Ä–∞–µ–º –¥–µ—Ç–µ–∫—Ü–∏—é —Å –Ω–∞–∏–±–æ–ª—å—à–µ–π —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å—é
            best_det = max(dog_detections, key=lambda x: x[1])
            bbox, conf, cls = best_det
            x1, y1, w_det, h_det = bbox
            x2, y2 = x1 + w_det, y1 + h_det
            
            # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –≤—ã–±—Ä–∞–Ω–Ω–æ–π –¥–µ—Ç–µ–∫—Ü–∏–∏
            cv2.rectangle(vis_frame, (x1, y1), (x2, y2), (0, 255, 0), 3)
            cv2.putText(vis_frame, f"DOG: {conf:.2f}", (x1, y1 - 30),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            
            if w_det >= 10 and h_det >= 10:
                cropped = frame[y1:y2, x1:x2]
                
                # –£–≤–µ–ª–∏—á–µ–Ω–∏–µ –º–µ–ª–∫–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
                scale_factor = 1.0
                if cropped.shape[0] < 100 or cropped.shape[1] < 100:
                    scale_factor = 2.0
                    cropped = cv2.resize(cropped, None, fx=scale_factor, fy=scale_factor,
                                       interpolation=cv2.INTER_LINEAR)
                
                if cropped.size > 0:
                    pose_results = self.pose_model(cropped, verbose=False)[0]
                    if pose_results.keypoints is not None and len(pose_results.keypoints) > 0:
                        kps = pose_results.keypoints[0].xy[0].cpu().numpy()
                        # –ú–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Ç–æ—á–µ–∫ –æ–±—Ä–∞—Ç–Ω–æ
                        if scale_factor != 1.0:
                            kps /= scale_factor
                        kps[:, 0] += x1
                        kps[:, 1] += y1
                        
                        full_kps = np.zeros((NUM_KEYPOINTS, 2))
                        valid = min(kps.shape[0], NUM_KEYPOINTS)
                        full_kps[:valid] = kps[:valid]
                        
                        # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Ç–æ—á–∫–∏ –¥–µ—Ñ–µ–∫–∞—Ü–∏–∏ (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω–µ –∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–∞)
                        if not self.defecation_point_fixed:
                            self.defecation_point = self._calculate_defecation_point(full_kps)
                        
                        # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
                        base_feat = extract_structured_features(full_kps)
                        delta_feat = base_feat - self.prev_dog_feats if self.prev_dog_feats is not None else np.zeros_like(base_feat)
                        self.prev_dog_feats = base_feat.copy()
                        self.window.append(np.concatenate([base_feat, delta_feat]))
                        
                        # –û—Ç—Ä–∏—Å–æ–≤–∫–∞ –∫–ª—é—á–µ–≤—ã—Ö —Ç–æ—á–µ–∫ —Å–æ–±–∞–∫–∏
                        for idx_pt, (px, py) in enumerate(full_kps):
                            if idx_pt >= NUM_KEYPOINTS:
                                break
                            color = self.dog_keypoint_colors[idx_pt]
                            cv2.circle(vis_frame, (int(px), int(py)), 6, color, -1)
        
        if full_kps is None:
            vis_frame = self._handle_no_dog_detection(vis_frame)
        
        # === –û–ë–†–ê–ë–û–¢–ö–ê –£–ë–û–†–ö–ò ===
        if self.defecation_point_fixed:
            for det in human_detections:
                bbox, conf, cls = det
                x1, y1, w_det, h_det = bbox
                x2, y2 = x1 + w_det, y1 + h_det
                if w_det >= 10 and h_det >= 10:
                    cropped_human = frame[y1:y2, x1:x2]
                    if cropped_human.size > 0:
                        pose_results = self.human_pose_model(cropped_human, verbose=False)[0]
                        if pose_results.keypoints is not None and len(pose_results.keypoints) > 0:
                            kps = pose_results.keypoints[0].xy[0].cpu().numpy()
                            kps[:, 0] += x1
                            kps[:, 1] += y1
                            
                            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –±–ª–∏–∑–æ—Å—Ç–∏ —Ä—É–∫
                            if self._is_hand_near_defecation_point(kps, self.defecation_point_fixed):
                                # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º duration_sec –ø–µ—Ä–µ–¥ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º
                                duration_sec = 0.0
                                if self.cleaning_frame_start is None:
                                    self.cleaning_frame_start = frame_count
                                else:
                                    duration_frames = frame_count - self.cleaning_frame_start
                                    duration_sec = duration_frames / self.fps
                                    if duration_frames >= self.cleaning_min_duration_frames:
                                        self.cleaning_detected = True
                                
                                # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–∫—Å—Ç —É–±–æ—Ä–∫–∏
                                cv2.putText(vis_frame, f"CLEANING: {duration_sec:.1f}s", (x1, y1 - 60),
                                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                            else:
                                self.cleaning_frame_start = None
        
        return vis_frame

    def run_video(self, in_path, out_path=None):
        print(f"üîç Processing video: {in_path}")
        cap = cv2.VideoCapture(in_path)
        
        if not cap.isOpened():
            raise ValueError("Error opening video file")
        
        # –ü–æ–ª—É—á–∞–µ–º FPS –≤–∏–¥–µ–æ
        self.fps = cap.get(cv2.CAP_PROP_FPS)
        if self.fps <= 0:
            self.fps = 30  # –∑–Ω–∞—á–µ–Ω–∏–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é, –µ—Å–ª–∏ FPS –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω
        
        # –û–±–Ω–æ–≤–ª—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –≤—Ä–µ–º–µ–Ω–∏ –≤ –∫–∞–¥—Ä–∞—Ö —Å —É—á–µ—Ç–æ–º —Ä–µ–∞–ª—å–Ω–æ–≥–æ FPS
        # frame_count —É—á–∏—Ç—ã–≤–∞–µ—Ç –≤—Å–µ –∫–∞–¥—Ä—ã –≤–∏–¥–µ–æ (–≤–∫–ª—é—á–∞—è –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ), –ø–æ—ç—Ç–æ–º—É
        # —Ä–∞—Å—á—ë—Ç –≤—Ä–µ–º–µ–Ω–∏ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∫–æ—Ä—Ä–µ–∫—Ç–µ–Ω: –≤—Ä–µ–º—è = frame_count / fps
        self.defecation_min_duration_frames = int(2 * self.fps)  # 2 —Å–µ–∫—É–Ω–¥—ã –¥–ª—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è –¥–µ—Ñ–µ–∫–∞—Ü–∏–∏
        self.cleaning_timeout_frames = int(60 * self.fps)  # 1 –º–∏–Ω—É—Ç–∞ (60 —Å–µ–∫—É–Ω–¥) –æ–∂–∏–¥–∞–Ω–∏—è —É–±–æ—Ä–∫–∏ –æ—Ç —Ö–æ–∑—è–∏–Ω–∞
        self.cleaning_min_duration_frames = int(5 * self.fps)  # 5 —Å–µ–∫—É–Ω–¥ –¥–ª—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è —É–±–æ—Ä–∫–∏
        self.min_defecation_interval_frames = int(20 * self.fps)  # 20 —Å–µ–∫—É–Ω–¥ –º–µ–∂–¥—É –¥–µ—Ñ–µ–∫–∞—Ü–∏—è–º–∏
        
        # –í—ã–≤–æ–¥–∏–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞—Ö –æ–±—Ä–∞–±–æ—Ç–∫–∏
        print(f"üìπ FPS –≤–∏–¥–µ–æ: {self.fps:.2f}, –ø—Ä–æ–ø—É—Å–∫ –∫–∞–¥—Ä–æ–≤: –∫–∞–∂–¥—ã–π {self.frame_skip}-–π –∫–∞–¥—Ä")
        print(f"‚è±Ô∏è  –¢–∞–π–º–∞—É—Ç —É–±–æ—Ä–∫–∏: {self.cleaning_timeout_frames} –∫–∞–¥—Ä–æ–≤ ({60} —Å–µ–∫—É–Ω–¥ —Ä–µ–∞–ª—å–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏)")
        
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        writer = cv2.VideoWriter(out_path, cv2.VideoWriter_fourcc(*'mp4v'), self.fps,
                                (int(cap.get(3)), int(cap.get(4)))) if out_path else None
        
        # –û—Ç–∫–ª—é—á–∞–µ–º tqdm –¥–ª—è Streamlit (–ø—Ä–æ–≥—Ä–µ—Å—Å –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç—Å—è –≤ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–µ)
        import sys
        is_streamlit = 'streamlit' in sys.modules
        pbar = tqdm(total=total_frames, desc="Processing frames", unit="frame", disable=is_streamlit)
        frame_count = 0  # —Å—á–µ—Ç—á–∏–∫ –∫–∞–¥—Ä–æ–≤
        
        # –í—ã–∑—ã–≤–∞–µ–º callback –¥–ª—è –Ω–∞—á–∞–ª—å–Ω–æ–≥–æ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ (0%)
        if self.progress_callback:
            try:
                import sys
                sys.stdout.write(f"[DETECTOR] –í—ã–∑—ã–≤–∞—é –Ω–∞—á–∞–ª—å–Ω—ã–π callback: 0% –∏–∑ {total_frames} –∫–∞–¥—Ä–æ–≤\n")
                sys.stdout.flush()
                self.progress_callback(0, total_frames, f"–ù–∞—á–∞–ª–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –≤–∏–¥–µ–æ... –í—Å–µ–≥–æ –∫–∞–¥—Ä–æ–≤: {total_frames}")
                sys.stdout.write(f"[DETECTOR] –ù–∞—á–∞–ª—å–Ω—ã–π callback –≤—ã–ø–æ–ª–Ω–µ–Ω —É—Å–ø–µ—à–Ω–æ\n")
                sys.stdout.flush()
            except Exception as e:
                import sys
                sys.stdout.write(f"[DETECTOR ERROR] –û—à–∏–±–∫–∞ –≤ –Ω–∞—á–∞–ª—å–Ω–æ–º callback: {e}\n")
                sys.stdout.flush()
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –¥–ª—è –≤—Ä–µ–º–µ–Ω–∏ —Å –º–æ–º–µ–Ω—Ç–∞ –¥–µ—Ñ–µ–∫–∞—Ü–∏–∏
        time_since_defecation_frames = 0
        last_vis_frame = None  # –î–ª—è –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∫–∞–¥—Ä–æ–≤
        
        try:
            while True:
                ret, frame = cap.read()
                if not ret:
                    break
                
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∫–∞–¥—Ä—ã –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è (–æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π N-–π –∫–∞–¥—Ä)
                if frame_count % self.frame_skip != 0:
                    # –î–ª—è –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∫–∞–¥—Ä–æ–≤ –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π –∫–∞–¥—Ä
                    if writer and last_vis_frame is not None:
                        writer.write(last_vis_frame)
                    elif writer:
                        writer.write(frame)  # –ï—Å–ª–∏ –Ω–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω–æ–≥–æ –∫–∞–¥—Ä–∞, –ø–∏—à–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª
                    frame_count += 1
                    pbar.update(1)
                    continue
                
                vis_frame = self.process_frame(frame, frame_count)
                last_vis_frame = vis_frame  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –¥–ª—è –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∫–∞–¥—Ä–æ–≤
                
                # –û–±–Ω–æ–≤–ª—è–µ–º –ø—Ä–æ–≥—Ä–µ—Å—Å –∫–∞–∂–¥—ã–µ 3 –∫–∞–¥—Ä–∞ –¥–ª—è –±–æ–ª–µ–µ —á–∞—Å—Ç—ã—Ö –æ–±–Ω–æ–≤–ª–µ–Ω–∏–π
                if self.progress_callback and (frame_count % 3 == 0 or frame_count == total_frames - 1):
                    progress_percent = min(int((frame_count + 1) / total_frames * 100), 99)  # –ú–∞–∫—Å–∏–º—É–º 99% –¥–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
                    try:
                        self.progress_callback(progress_percent, total_frames, f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–¥—Ä–∞ {frame_count + 1} –∏–∑ {total_frames}")
                    except Exception as e:
                        import sys
                        sys.stdout.write(f"[DETECTOR ERROR] –û—à–∏–±–∫–∞ –≤ callback –ø—Ä–æ–≥—Ä–µ—Å—Å–∞: {e}\n")
                        sys.stdout.flush()
                
                if len(self.window) == self.window.maxlen:
                    seq = torch.tensor(np.array(self.window), dtype=torch.float32).unsqueeze(0).to(self.device)
                    with torch.no_grad():
                        prob = torch.sigmoid(self.net(seq)).item()
                    self.hist.append(prob)
                    avg_prob = np.mean(self.hist[-self.smooth:] or [0])
                    
                    # =============================================================
                    # –õ–û–ì–ò–ö–ê –û–ë–†–ê–ë–û–¢–ö–ò –°–û–ë–´–¢–ò–ô (–ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø)
                    # =============================================================
                    # –õ–æ–≥–∏–∫–∞ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è –¥–µ—Ñ–µ–∫–∞—Ü–∏–∏ (–≤ –∫–∞–¥—Ä–∞—Ö)
                    if avg_prob > self.threshold:
                        # –ù–∞—á–∞–ª–æ –∞–ª–µ—Ä—Ç–∞ –∏–ª–∏ –æ–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏—è
                        if self.alert_frame_start is None:
                            self.alert_frame_start = frame_count
                            print(f"üö® Alert started at frame {frame_count} (prob: {avg_prob:.4f})")
                        
                        # –í—Å–µ–≥–¥–∞ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Å—Ç–∞—Ç—É—Å ALERT –ø—Ä–∏ –ø—Ä–µ–≤—ã—à–µ–Ω–∏–∏ –ø–æ—Ä–æ–≥–∞
                        self.alert = True
                        
                        # –í—ã—á–∏—Å–ª—è–µ–º –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –∞–ª–µ—Ä—Ç–∞ –≤ –∫–∞–¥—Ä–∞—Ö
                        alert_duration_frames = frame_count - self.alert_frame_start
                        
                        # –£—Å–ª–æ–≤–∏–µ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è –¥–µ—Ñ–µ–∫–∞—Ü–∏–∏
                        if (alert_duration_frames >= self.defecation_min_duration_frames and 
                            self.defecation_point is not None):
                            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∏–Ω—Ç–µ—Ä–≤–∞–ª —Å –ø–æ—Å–ª–µ–¥–Ω–µ–π –¥–µ—Ñ–µ–∫–∞—Ü–∏–∏
                            if (self.last_defecation_frame == 0 or  # –ü–µ—Ä–≤–∞—è –¥–µ—Ñ–µ–∫–∞—Ü–∏—è
                                frame_count - self.last_defecation_frame > self.min_defecation_interval_frames):
                                self.defecation_confirmed = True
                                self.defecation_point_fixed = self.defecation_point
                                self.defecation_frame_fixed = frame_count
                                self.last_defecation_frame = frame_count
                                print(f"üí© Defecation CONFIRMED at frame {frame_count}! "
                                      f"Point: {self.defecation_point_fixed}")
                            else:
                                print(f"‚ö†Ô∏è Defecation detected but too soon: "
                                      f"{frame_count - self.last_defecation_frame}/"
                                      f"{self.min_defecation_interval_frames} frames")
                    else:
                        # –°–±—Ä–∞—Å—ã–≤–∞–µ–º –∞–ª–µ—Ä—Ç –ø—Ä–∏ –ø–∞–¥–µ–Ω–∏–∏ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –Ω–∏–∂–µ –ø–æ—Ä–æ–≥–∞
                        if self.alert_frame_start is not None:
                            print(f"‚úÖ Alert ended at frame {frame_count} (prob: {avg_prob:.4f})")
                            self.alert_frame_start = None
                            self.alert = False
                            self.defecation_confirmed = False
                    
                    # –í—ã—á–∏—Å–ª—è–µ–º –≤—Ä–µ–º—è —Å –º–æ–º–µ–Ω—Ç–∞ –¥–µ—Ñ–µ–∫–∞—Ü–∏–∏, –µ—Å–ª–∏ –∑–æ–Ω–∞ –∑–∞—Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–∞
                    # frame_count —É—á–∏—Ç—ã–≤–∞–µ—Ç –≤—Å–µ –∫–∞–¥—Ä—ã –≤–∏–¥–µ–æ (–≤–∫–ª—é—á–∞—è –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ),
                    # –ø–æ—ç—Ç–æ–º—É —Ä–∞—Å—á—ë—Ç –≤—Ä–µ–º–µ–Ω–∏ –∫–æ—Ä—Ä–µ–∫—Ç–µ–Ω: —Ä–µ–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è = frame_count / fps
                    if self.defecation_point_fixed:
                        # –†–∞–∑–Ω–∏—Ü–∞ –≤ –∫–∞–¥—Ä–∞—Ö (—É—á–∏—Ç—ã–≤–∞–µ—Ç –≤—Å–µ –∫–∞–¥—Ä—ã, –≤–∫–ª—é—á–∞—è –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ)
                        time_since_defecation_frames = frame_count - self.defecation_frame_fixed
                        # –†–µ–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è –≤ —Å–µ–∫—É–Ω–¥–∞—Ö —Å —É—á—ë—Ç–æ–º FPS –≤–∏–¥–µ–æ
                        time_since_defecation_sec = time_since_defecation_frames / self.fps
                    else:
                        time_since_defecation_frames = 0
                        time_since_defecation_sec = 0.0
                    
                    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞—Ä—É—à–µ–Ω–∏—è (–≤ –∫–∞–¥—Ä–∞—Ö)
                    # –ù–∞—Ä—É—à–µ–Ω–∏–µ —Ñ–∏–∫—Å–∏—Ä—É–µ—Ç—Å—è —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –ø—Ä–æ—à–ª–∞ 1 –º–∏–Ω—É—Ç–∞ (60 —Å–µ–∫—É–Ω–¥) –±–µ–∑ —É–±–æ—Ä–∫–∏
                    violation = False
                    if self.defecation_point_fixed:
                        if (time_since_defecation_frames >= self.cleaning_timeout_frames and 
                            not self.cleaning_detected):
                            violation = True
                            self.violation_active = True
                            
                            # –ù–∞—á–∏–Ω–∞–µ–º –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –ø–µ—Ä–∏–æ–¥–∞ –Ω–∞—Ä—É—à–µ–Ω–∏—è
                            if self.violation_start_frame is None:
                                self.violation_start_frame = frame_count
                                # –í—ã–≤–æ–¥–∏–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é —Å —É—á—ë—Ç–æ–º —Ä–µ–∞–ª—å–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ –≤–∏–¥–µ–æ
                                print(f"‚õî VIOLATION started at frame {frame_count} "
                                      f"(—á–µ—Ä–µ–∑ {time_since_defecation_sec:.1f} —Å–µ–∫ —Ä–µ–∞–ª—å–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ –ø–æ—Å–ª–µ –¥–µ—Ñ–µ–∫–∞—Ü–∏–∏, "
                                      f"FPS: {self.fps:.2f}, –ø—Ä–æ–ø—É—Å–∫: {self.frame_skip})!")
                        else:
                            # –ï—Å–ª–∏ –Ω–∞—Ä—É—à–µ–Ω–∏–µ –±—ã–ª–æ –∞–∫—Ç–∏–≤–Ω–æ, –Ω–æ —Ç–µ–ø–µ—Ä—å —É–±–æ—Ä–∫–∞ –Ω–∞—á–∞–ª–∞—Å—å –∏–ª–∏ –∑–æ–Ω–∞ —Å–±—Ä–æ—à–µ–Ω–∞
                            if self.violation_active and self.violation_start_frame is not None:
                                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–µ—Ä–∏–æ–¥ –Ω–∞—Ä—É—à–µ–Ω–∏—è
                                self.violation_periods.append((self.violation_start_frame, frame_count))
                                print(f"‚õî VIOLATION period recorded: frames {self.violation_start_frame} - {frame_count}")
                                self.violation_start_frame = None
                    
                    # –°–±—Ä–æ—Å –∑–æ–Ω—ã –ø—Ä–∏ —É–±–æ—Ä–∫–µ –∏–ª–∏ –ø–æ –∏—Å—Ç–µ—á–µ–Ω–∏–∏ –≤—Ä–µ–º–µ–Ω–∏
                    if (self.cleaning_detected or 
                        (self.defecation_point_fixed and 
                         time_since_defecation_frames > self.cleaning_timeout_frames + 5 * self.fps)):
                        print(f"üîÑ Resetting defecation zone at frame {frame_count}")
                        
                        # –ï—Å–ª–∏ –±—ã–ª –∞–∫—Ç–∏–≤–Ω—ã–π –ø–µ—Ä–∏–æ–¥ –Ω–∞—Ä—É—à–µ–Ω–∏—è, —Å–æ—Ö—Ä–∞–Ω—è–µ–º –µ–≥–æ
                        if self.violation_active and self.violation_start_frame is not None:
                            self.violation_periods.append((self.violation_start_frame, frame_count))
                            print(f"‚õî VIOLATION period recorded: frames {self.violation_start_frame} - {frame_count}")
                            self.violation_start_frame = None
                        
                        self.defecation_point_fixed = None
                        self.cleaning_detected = False
                        self.cleaning_frame_start = None
                        violation = False  # –°–±—Ä–æ—Å–∏–º violation, —Ç–∞–∫ –∫–∞–∫ –∑–æ–Ω–∞ —Å–±—Ä–æ—à–µ–Ω–∞
                        self.violation_active = False
                    
                    # =============================================================
                    # –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø –°–¢–ê–¢–£–°–û–í
                    # =============================================================
                    # –£–ø—Ä–æ—â–µ–Ω–Ω—ã–µ —Å—Ç–∞—Ç—É—Å—ã –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
                    status_lines = []
                    colors = []
                    
                    # –°—Ç–∞—Ç—É—Å —Å–æ–±–∞–∫–∏
                    status_lines.append(f"DOG: {'ALERT' if self.alert else 'NORMAL'} {avg_prob:.2f}")
                    colors.append((0, 0, 255) if self.alert else (0, 255, 0))
                    
                    # –°—Ç–∞—Ç—É—Å –¥–µ—Ñ–µ–∫–∞—Ü–∏–∏
                    if self.defecation_confirmed:
                        status_lines.append("DEFECATION: CONFIRMED")
                        colors.append((0, 255, 0))
                    elif self.alert:
                        # –í—ã—á–∏—Å–ª—è–µ–º –æ—Å—Ç–∞–≤—à–µ–µ—Å—è –≤—Ä–µ–º—è –¥–æ –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è
                        if self.alert_frame_start is not None:
                            alert_duration_frames = frame_count - self.alert_frame_start
                            if alert_duration_frames < self.defecation_min_duration_frames:
                                pending_sec = (self.defecation_min_duration_frames - alert_duration_frames) / self.fps
                                status_lines.append(f"DEFECATION: PENDING ({pending_sec:.1f}s)")
                            else:
                                # –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –Ω–∞–±—Ä–∞–Ω–∞, –Ω–æ –Ω–µ—Ç —Ç–æ—á–∫–∏ –¥–µ—Ñ–µ–∫–∞—Ü–∏–∏
                                status_lines.append("DEFECATION: PENDING (needs point)")
                        else:
                            status_lines.append("DEFECATION: PENDING")
                        colors.append((0, 165, 255))
                    
                    # –°—Ç–∞—Ç—É—Å —É–±–æ—Ä–∫–∏
                    # –†–∞—Å—á—ë—Ç –æ—Å—Ç–∞–≤—à–µ–≥–æ—Å—è –≤—Ä–µ–º–µ–Ω–∏ —Å —É—á—ë—Ç–æ–º FPS –∏ –ø—Ä–æ–ø—É—Å–∫–∞ –∫–∞–¥—Ä–æ–≤
                    # frame_count —É—á–∏—Ç—ã–≤–∞–µ—Ç –≤—Å–µ –∫–∞–¥—Ä—ã (–≤–∫–ª—é—á–∞—è –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ), –ø–æ—ç—Ç–æ–º—É
                    # —Ä–∞—Å—á—ë—Ç –≤—Ä–µ–º–µ–Ω–∏ –∫–æ—Ä—Ä–µ–∫—Ç–µ–Ω: —Ä–µ–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è = –∫–∞–¥—Ä—ã / fps
                    if self.defecation_point_fixed:
                        # –û—Å—Ç–∞–≤—à–µ–µ—Å—è –≤—Ä–µ–º—è –¥–æ —Ç–∞–π–º–∞—É—Ç–∞ (–≤ —Å–µ–∫—É–Ω–¥–∞—Ö —Ä–µ–∞–ª—å–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏)
                        time_left_sec = (self.cleaning_timeout_frames - time_since_defecation_frames) / self.fps
                        if self.cleaning_detected:
                            status_lines.append("CLEANING: CLEANED")
                            colors.append((0, 255, 0))
                        else:
                            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –æ—Å—Ç–∞–≤—à–µ–µ—Å—è –≤—Ä–µ–º—è —Å —Ç–æ—á–Ω–æ—Å—Ç—å—é –¥–æ 0.1 —Å–µ–∫—É–Ω–¥—ã
                            status_lines.append(f"CLEANING: WAITING {max(0, time_left_sec):.1f}s")
                            colors.append((0, 0, 255))
                    
                    # –°—Ç–∞—Ç—É—Å –Ω–∞—Ä—É—à–µ–Ω–∏—è
                    if violation:
                        status_lines.append("VIOLATION: DETECTED!")
                        colors.append((0, 0, 255))
                    
                    # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–æ–≤
                    for i, (text, color) in enumerate(zip(status_lines, colors)):
                        cv2.putText(vis_frame, text, (20, 30 + i*30),
                                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)
                    
                    # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–π –∑–æ–Ω—ã –ö–í–ê–î–†–ê–¢–û–ú
                    if self.defecation_point_fixed:
                        # –†–∞–∑–º–µ—Ä –∫–≤–∞–¥—Ä–∞—Ç–∞ (—É–≤–µ–ª–∏—á–∏–≤–∞–µ–º –¥–ª—è –ª—É—á—à–µ–π –≤–∏–¥–∏–º–æ—Å—Ç–∏)
                        zone_size = 80
                        x_center, y_center = self.defecation_point_fixed
                        # –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –∫–≤–∞–¥—Ä–∞—Ç–∞
                        x1 = int(x_center - zone_size/2)
                        y1 = int(y_center - zone_size/2)
                        x2 = int(x_center + zone_size/2)
                        y2 = int(y_center + zone_size/2)
                        # –†–∏—Å—É–µ–º –∫—Ä–∞—Å–Ω—ã–π –∫–≤–∞–¥—Ä–∞—Ç —Å –±–æ–ª–µ–µ —Ç–æ–ª—Å—Ç–æ–π –ª–∏–Ω–∏–µ–π
                        cv2.rectangle(vis_frame, (x1, y1), (x2, y2), (0, 0, 255), 4)
                        # –ó–∞–ª–∏–≤–∫–∞ –ø–æ–ª—É–ø—Ä–æ–∑—Ä–∞—á–Ω—ã–º –∫—Ä–∞—Å–Ω—ã–º
                        overlay = vis_frame.copy()
                        cv2.rectangle(overlay, (x1, y1), (x2, y2), (0, 0, 255), -1)
                        cv2.addWeighted(overlay, 0.3, vis_frame, 0.7, 0, vis_frame)
                        # –ü–æ–¥–ø–∏—Å—å –∑–æ–Ω—ã
                        cv2.putText(vis_frame, "DEFECATION ZONE", (x1, y1 - 15),
                                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 3)
                        # –†–∏—Å—É–µ–º –∫—Ä–µ—Å—Ç–∏–∫ –≤ —Ü–µ–Ω—Ç—Ä–µ –∑–æ–Ω—ã
                        cross_size = 20
                        cv2.line(vis_frame, 
                                (int(x_center - cross_size), int(y_center)),
                                (int(x_center + cross_size), int(y_center)),
                                (255, 255, 255), 3)
                        cv2.line(vis_frame,
                                (int(x_center), int(y_center - cross_size)),
                                (int(x_center), int(y_center + cross_size)),
                                (255, 255, 255), 3)
                
                if writer:
                    writer.write(vis_frame)
                else:
                    cv2.imshow('Dog Monitoring System', vis_frame)
                    if cv2.waitKey(1) == ord('q'):
                        break
                
                pbar.update(1)
                frame_count += 1  # —É–≤–µ–ª–∏—á–∏–≤–∞–µ–º —Å—á–µ—Ç—á–∏–∫ –∫–∞–¥—Ä–æ–≤
        
        finally:
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–π –ø–µ—Ä–∏–æ–¥ –Ω–∞—Ä—É—à–µ–Ω–∏—è, –µ—Å–ª–∏ –æ–Ω –∞–∫—Ç–∏–≤–µ–Ω
            if self.violation_active and self.violation_start_frame is not None:
                self.violation_periods.append((self.violation_start_frame, frame_count))
                print(f"‚õî VIOLATION period recorded (final): frames {self.violation_start_frame} - {frame_count}")
            
            # –í—ã–∑—ã–≤–∞–µ–º callback –¥–ª—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è (100%)
            if self.progress_callback:
                try:
                    self.progress_callback(100, total_frames, "–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
                except Exception as e:
                    print(f"–û—à–∏–±–∫–∞ –≤ —Ñ–∏–Ω–∞–ª—å–Ω–æ–º callback: {e}")
            
            cap.release()
            if writer:
                writer.release()
            try:
                cv2.destroyAllWindows()
            except:
                pass  # –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –æ—à–∏–±–∫–∏ –≤ Streamlit
            pbar.close()
        
        # –ù–µ –≤—ã–≤–æ–¥–∏–º print –≤ Streamlit, —á—Ç–æ–±—ã –Ω–µ –∑–∞—Å–æ—Ä—è—Ç—å –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
        # print(f"‚úÖ Processing completed. Total frames: {total_frames}")

